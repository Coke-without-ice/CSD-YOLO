CSD-YOLO is an improved object detection model based on YOLO11n, which enhances the ability to detect small objects while reducing parameters and computational load. It adopts the fusion Maximum Sampling (CMDown) module to optimize the sampling strategy and increase the sensitivity to tiny targets. The designed spatial position enhancement multi-dimensional attention module (SELA) enables the network to focus more on key information and enhances the ability to detect small targets. C3K2 combined with SAConv reduces the computational load while maintaining the feature extraction capability. Design the lightweight neck network NtNeck to reduce the computational load and parameters while maintaining the model's accuracy without excessive loss. The improved SFIoU further realizes the refined regression of bounding boxes in the object detection task. These improvements make the CSD-YOLO more lightweight while achieving greater accuracy in small target detection.
![绘图13](https://github.com/user-attachments/assets/a65db834-f4aa-4528-9ef8-bf0dacfe7583)
Table 1 presents a detailed comparison and analysis of the performance of different YOLO versions, leveraging the YOLO algorithm within a stable environmental setting. As evident from the data, under identical environmental conditions and training configurations, CSD-YOLO demonstrates superior performance in extracting small targets, outperforming both YOLOv11 and YOLOv12 models. Notably, in comparison with YOLOv11, CSD-YOLO exhibits a reduction of 5.79% in the number of parameters, a decrease of 9.38% in floating-point calculations, and a remarkable increase of 2.41% in mAP50. These compelling statistics underscore the significant advancements made by CSD-YOLO in recognizing small targets, thereby offering a more efficient and precise approach to target detection.
Table 1 
Comparison of Some Object detection Algorithms in the Visdrone2019 dataset
<img width="1477" height="501" alt="image" src="https://github.com/user-attachments/assets/92b3803d-c6b5-423a-95bc-6b68a9d7ee72" />
![image](https://github.com/user-attachments/assets/06ab3f9f-b359-4b83-a4e6-0267943d7153)
The gradient weighted class activation mapping module (Grad-CAM) was adopted to generate the heat maps of YOLOv11n and replace C2PSA in YOLOv11n with SELA. Photos of the inspected vehicles, people and night scenes were selected respectively, and the results are shown in Fig. 11. The original YOLO11n has limitations when detecting small objects and is prone to missed detections. When the attention is changed to SELA, it pays more attention to small targets, predicts bounding boxes more accurately, and the model performance is significantly improved.
![image](https://github.com/user-attachments/assets/5441d0d9-7ee6-4a33-b7f9-f91d4e406154)

